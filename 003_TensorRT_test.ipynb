{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## docker run -it --gpus all --rm -v $PWD:/tf/host -p 8585:8888 tensorflow/tensorflow:latest-gpu-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.2.2 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q jupyter-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 746 ms (2022-08-23T03:32:28/2022-08-23T03:32:29)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-3b49e2b8-87f0-c515-798b-3492ec05a183)\r\n",
      "GPU 1: NVIDIA GeForce GTX 1080 Ti (UUID: GPU-07628ed7-6ef8-fd67-7d03-cb6a89f72de4)\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "!nvidia-smi -L\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 2.1 s (2022-08-23T03:32:29/2022-08-23T03:32:31)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from pathlib import Path\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 72.9 ms (2022-08-23T03:32:31/2022-08-23T03:32:31)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.get_visible_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 863 µs (2022-08-23T03:32:32/2022-08-23T03:32:32)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_dir_size(directory):\n",
    "    root_dir=Path(\".\")\n",
    "    size = sum(f.stat().st_size for f in root_dir.glob(directory+'/**/*') if f.is_file())\n",
    "    return f\"Size in MB: {size // (1024*1024)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 514 µs (2022-08-23T03:32:32/2022-08-23T03:32:32)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_path = \"./dataset/data_splitting/Train/\"\n",
    "valid_path = \"./dataset/data_splitting/Test/\"\n",
    "test_path = \"./dataset/data_splitting/Pred/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 619 µs (2022-08-23T03:32:32/2022-08-23T03:32:32)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can add more augmentations, if you want\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 6.74 ms (2022-08-23T03:32:32/2022-08-23T03:32:32)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['aegypti landing',\n",
       " 'aegypti smashed',\n",
       " 'albopictus landing',\n",
       " 'albopictus smashed',\n",
       " 'Culex landing',\n",
       " 'Culex smashed']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetMap='''aegypti landing\n",
    "aegypti smashed\n",
    "albopictus landing\n",
    "albopictus smashed\n",
    "Culex landing\n",
    "Culex smashed'''.split('\\n')\n",
    "targetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 2.45 ms (2022-08-23T03:32:32/2022-08-23T03:32:32)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyper-Parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "NUM_CLASSES = len(targetMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 662 ms (2022-08-23T03:32:33/2022-08-23T03:32:33)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4200 images belonging to 6 classes.\n",
      "Found 1799 images belonging to 6 classes.\n",
      "Found 3600 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory(train_path, target_size=IMG_SIZE,\n",
    "                                      classes=targetMap, class_mode='categorical', batch_size=BATCH_SIZE)\n",
    "valid = gen.flow_from_directory(valid_path, target_size=IMG_SIZE,\n",
    "                                      classes=targetMap, class_mode='categorical', batch_size=BATCH_SIZE)\n",
    "test = gen.flow_from_directory(test_path, target_size=IMG_SIZE,\n",
    "                                      classes=targetMap, class_mode='categorical', batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 1 s (2022-08-23T03:34:35/2022-08-23T03:34:36)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"./optimized/pruned_model/\", compile=False)\n",
    "# For evaluation, you must run compile again (but don't need it for production as you only use predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 18.5 s (2022-08-23T03:32:36/2022-08-23T03:32:54)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    imgs, _ = test.next()\n",
    "    for img in imgs:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        model.predict(img, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHOUT prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 755 µs (2022-08-23T03:34:22/2022-08-23T03:34:22)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fmd = \"./mlflow/artifacts/1/38162c8d183043f1bfddf866e1ee9175/artifacts/model/data/model\" #final model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 1.31 s (2022-08-23T03:34:49/2022-08-23T03:34:51)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noprun = keras.models.load_model(\"./optimized/pruned_model/\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 27 min 2 s (2022-08-23T03:54:41/2022-08-23T04:21:44)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    imgs, _ = test.next()\n",
    "    for img in imgs:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        model.predict(img, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 2.13 ms (2022-08-23T03:38:17/2022-08-23T03:38:17)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 983 µs (2022-08-23T03:40:32/2022-08-23T03:40:32)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "    precision_mode='FP16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 6.77 ms (2022-08-23T03:41:52/2022-08-23T03:41:52)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size in MB: 38'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dir_size(\"./optimized/pruned_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 3.38 s (2022-08-23T03:40:47/2022-08-23T03:40:50)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 2, 2)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 2, 2)\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_000 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./optimized/optimized_for_latency/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./optimized/optimized_for_latency/assets\n"
     ]
    }
   ],
   "source": [
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=\"./optimized/pruned_model/\")\n",
    "converter.convert()\n",
    "converter.save(\"./optimized/optimized_for_latency/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 7.76 ms (2022-08-23T03:41:18/2022-08-23T03:41:18)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size in MB: 76'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dir_size(\"./optimized/optimized_for_latency/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 1.25 s (2022-08-23T03:50:00/2022-08-23T03:50:02)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latency = tf.saved_model.load(\"./optimized/optimized_for_latency/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 2.07 ms (2022-08-23T03:50:50/2022-08-23T03:50:50)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer = latency.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 2 min 14 s (2022-08-23T03:52:26/2022-08-23T03:54:41)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    imgs, _ = test.next()\n",
    "    for img in imgs:\n",
    "        img = tf.expand_dims(img, axis=0)\n",
    "        infer(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT Pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 2.49 ms (2022-08-23T04:26:56/2022-08-23T04:26:56)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prune_custom_layer(layer):\n",
    "    # prunning_params is optional (don't use it if you want)\n",
    "#     end_step = np.ceil(train.n/BATCH_SIZE).astype(np.int32) * EPOCHS\n",
    "#     prunning_params = {\n",
    "#         tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.5, \n",
    "#                                              final_sparsity=0.9,\n",
    "#                                              begin_step=0,\n",
    "#                                             end_step=end_step)\n",
    "#     }\n",
    "    try:\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **prunning_params)\n",
    "    except:\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 27.6 ms (2022-08-23T04:27:26/2022-08-23T04:27:26)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected `model` argument to be a `Model` instance. Received: model=<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7fe93476d9a0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-874538da2521>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = tf.keras.models.clone_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlatency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclone_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_custom_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/models/cloning.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    446\u001b[0m           model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[1;32m    447\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m       return _clone_functional_model(\n\u001b[0m\u001b[1;32m    449\u001b[0m           model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/models/cloning.py\u001b[0m in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    149\u001b[0m   \"\"\"\n\u001b[1;32m    150\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     raise ValueError('Expected `model` argument '\n\u001b[0m\u001b[1;32m    152\u001b[0m                      f'to be a `Model` instance. Received: model={model}')\n\u001b[1;32m    153\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected `model` argument to be a `Model` instance. Received: model=<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7fe93476d9a0>"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.clone_model(\n",
    "    latency,\n",
    "    clone_function=prune_custom_layer\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
